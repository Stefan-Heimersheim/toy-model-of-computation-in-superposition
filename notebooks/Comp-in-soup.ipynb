{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21db3e71-b540-49cf-98ab-3c5273aaa123",
   "metadata": {},
   "source": [
    "# TIDY NOTEBOOK TO MAKE ALL FIGURES FOR PAPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b6dcda4-f7bb-4742-9d95-517023950c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device_name='NVIDIA A40'\n"
     ]
    }
   ],
   "source": [
    "# Set up notebook\n",
    "\n",
    "\"\"\"Import necessary packages\"\"\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Callable, List, Optional, Tuple, Union\n",
    "\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as t\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from einops import asnumpy, einsum, rearrange, reduce, repeat, pack, parse_shape, unpack\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "from jaxtyping import Float, Int\n",
    "from matplotlib import pyplot as plt\n",
    "from plotly import express as px\n",
    "from plotly import graph_objects as go\n",
    "from plotly import io as pio\n",
    "from rich import print as rprint\n",
    "import seaborn as sns\n",
    "from torch import nn, optim, Tensor\n",
    "from torch.nn import functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from toy_cis.models import CisConfig, Cis\n",
    "from toy_cis.plot import plot_loss_across_sparsities, plot_input_output_response, plot_weight_bars\n",
    "from toy_cis.util import threshold_matrix, in_out_response, performance_across_sparsities\n",
    "\n",
    "\"\"\"Set KMP_DUPLICATE_LIB_OK=TRUE to avoid MKL errors when plotting with mpl\"\"\"\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"True\"\n",
    "plt.rcParams.update({\"font.size\": 16})\n",
    "\n",
    "\"\"\"Set torch device.\"\"\"\n",
    "\n",
    "device = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")\n",
    "# device = t.device(\"cpu\")  # small toy models have lower loss and are faster via cpu\n",
    "device_name = t.cuda.get_device_name(0) if t.cuda.is_available() else \"cpu\"\n",
    "print(f\"{device_name=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1943e1f9-6d54-498f-a5b2-14e9603fe881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "\n",
    "\"\"\"ReLU + x model with Identity embedding\"\"\"\n",
    "layer_act_fns = [t.relu, lambda x: x]\n",
    "\n",
    "reluPlusX_res_noEmbed_cfg = CisConfig(\n",
    "    n_instances=1,\n",
    "    n_feat=100,\n",
    "    n_hidden=50,\n",
    "    act_fn=layer_act_fns,\n",
    "    b1=None,\n",
    "    b2=None,\n",
    "    skip_cnx=True,\n",
    "    We_and_Wu=False,\n",
    ")\n",
    "name = \"ReluPlusX_NoEmbedding\"\n",
    "\n",
    "\n",
    "\"\"\"ReLU + x model with Random embedding\"\"\"\n",
    "layer_act_fns = [t.relu, lambda x: x]\n",
    "\n",
    "reluPlusX_res_embed_cfg = CisConfig(\n",
    "    n_instances=1,\n",
    "    n_feat=100,\n",
    "    n_hidden=50,\n",
    "    act_fn=layer_act_fns,\n",
    "    b1=None,\n",
    "    b2=None,\n",
    "    skip_cnx=True,\n",
    "    We_and_Wu=True,\n",
    "    We_dim=1000\n",
    ")\n",
    "name = \"ReluPlusX_WithEmbedding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "576c159d-b83b-4781-9c4d-46568686a7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a model to train and explore characteristics\n",
    "\"\"\"Select the model configuration\"\"\"\n",
    "model_cfg = reluPlusX_res_embed_cfg\n",
    "\n",
    "\"\"\"Select the feature probability of the training input.\"\"\"\n",
    "feat_sparsity = 0.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6086669a-90bd-4ed0-afc2-76fdd17fe18a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b2ef00dd4a640028109968927ebda4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train model\n",
    "\n",
    "\"\"\"Training hyperparameters\"\"\"\n",
    "feat_prob = 1 - feat_sparsity\n",
    "batch_sz = 2048\n",
    "feat_importance = 1\n",
    "lr = 3e-3\n",
    "n_steps = 10000\n",
    "logging_freq = n_steps // 10\n",
    "\n",
    "model = Cis(model_cfg, device=device, name=name )\n",
    "\n",
    "losses = model.train_reluPlusX(\n",
    "        batch_sz,\n",
    "        feat_sparsity,\n",
    "        feat_importance,\n",
    "        n_steps,\n",
    "        lr, \n",
    "        logging_freq, \n",
    ")\n",
    "display(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a833cdb-9ccc-4422-bd98-8c7899540dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Compute and plot the model's performance across sparsities.\"\"\"\n",
    "\n",
    "sparsity_low = np.round(np.linspace(0.0,0.8,9),2)\n",
    "sparsity_high = np.round(np.linspace(0.8,0.99,20),2)\n",
    "sparsities = np.unique(np.concatenate((sparsity_low,sparsity_high)))\n",
    "batch_sz = 256\n",
    "feat_importance = 1\n",
    "\n",
    "loss_data = performance_across_sparsities(sparsities, model)\n",
    "\n",
    "\"\"\"Plot performance across different input sparsities\"\"\"\n",
    "fig = plot_loss_across_sparsities(loss_data, sparsities, model.name, feat_sparsity)\n",
    "\n",
    "# save figure and show\n",
    "filename = f\"/workspace/{model.name}_S{feat_prob:.2f}_loss_plot.png\" \n",
    "plt.savefig(filename, dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf95f5b-d200-4104-b605-00822c027feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Compute and plot input-output response profile.\"\"\"\n",
    "\n",
    "vals = t.linspace(-1, 1, 100, device=device)  # input values\n",
    "Y = in_out_response(model, vals, device)\n",
    "\n",
    "fig = plot_input_output_response(Y, vals, model.name, feat_prob, losses)\n",
    "\n",
    "# save figure and show\n",
    "filename = f\"/workspace/{model.name}_S{feat_prob:.2f}_input_output_response.png\" \n",
    "plt.savefig(filename, dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b816c118-2516-4246-9c90-7f5d10f8ab6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Extract and plot weights.\"\"\"\n",
    "\n",
    "if model.cfg.We_and_Wu == True: \n",
    "    W_feat_to_neuron = einsum(model.We, model.W1,\n",
    "                          \"inst emb feat, inst neuron emb -> neuron feat\")\n",
    "    W_neuron_to_feat = einsum(model.W2, model.Wu,\n",
    "                          \"inst emb neuron, inst feat emb -> feat neuron\")\n",
    "    W = einsum(W_feat_to_neuron, W_neuron_to_feat, \"neuron feat, feat neuron -> feat neuron\")\n",
    "else:\n",
    "    W = einsum(model.W1, model.W2, \n",
    "               \"inst neuron feature, inst feature neuron-> neuron feature\")\n",
    "    \n",
    "W = threshold_matrix(W.squeeze(), threshold=0.001)\n",
    "\n",
    "print(f\"{W.shape=}\")\n",
    "\n",
    "fig = plot_weight_bars(W.T, xax=\"feature\", model_name=model.name, feat_prob=feat_prob)\n",
    "filename = f\"/workspace/{model.name}_S{feat_prob:.2f}_weights_per_feature.png\" \n",
    "plt.savefig(filename, dpi=300)\n",
    "plt.show\n",
    "\n",
    "fig = plot_weight_bars(W, xax=\"neuron\", model_name=model.name, feat_prob=feat_prob)\n",
    "filename = f\"/workspace/{model.name}_S{feat_prob:.2f}_weights_per_neuron.png\" \n",
    "plt.savefig(filename, dpi=300)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77130446-0dd7-4a31-baa5-2ff7e70f7f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Plot a phase diagram of loss of training sparsity vs input sparsity performance\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4297f7-a8ac-40f1-8d3a-33ec573b39ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Pixi)",
   "language": "python",
   "name": "pixi-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
